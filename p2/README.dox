/**

@mainpage 15-410 Project 2

@author Nicklaus Choo (nchoo)
@author Andre Nascimento (anascime)


## Illegal operations

Our approach to illegal operations is to do everything in our immediate means to
deal with them. Some illegal operations, however, are quite hard to deal with
such as locking a mutex which is being destroyed. To the extent possible we
panic and crash the application in these cases, but at times, it simply leads
to undocumented behavior. We believe this is reasonable as the resources
required to better deal with these errors are not worth pursuing:
it's not reasonable to lockdown the entire park and begin an investigation
because someone littered. It's also not reasonable to have a guard closely
monitoring each visitant to stop them and deal with their littering.


## Error handling

We performed case analysis on how to deal with each bug. We have found, though,
that in the vast majority of cases, we return -1 on functions that are allowed
to fail and we crash on those that can't if we face an unfixable error. Also,
whenever we encounter a bug we make sure to cleanup all resources in use.
A notable case is locks: In case lock fails, it always crashes as a silent
return would give a thread the wrong notion that it has exclusive access to
the critical section.

When a given thread crashes, we call task void and print out to the user both
the panic message and the ID of the thread calling panic. The kernel is then
responsible for cleaning up.


## With respect to dynamic memory allocation

A global mutex is used to ensure mutual exclusion when calling any malloc
family of functions. This ensures thread-safety as we will never context
switch away in the middle of a malloc() call and again perform another
malloc() call.


## On synchronization concerns

We avoid using global locks as much as possible. With respect to the thread
library, we use a lock to store and retrieve shared status information. For
the malloc library we also use a global lock to avoid making any assumptions
about the provided malloc code. Using a global lock allows us to serialize
requests and have the same behavior as that of a single thread using malloc.

----- BELOW WE LIST ALL COMPONENTS OF THE CODE AND THE DESIGN BEHIND THEM -----


## Hashmap for thread control blocks

The hashmap is implemented as an array of linked lists. Its size
is fixed to 1024, a reasonable number to avoid collisions. As
they lead to longer lookup times (linked list traversal).  We
use a hash function defined in github.com/skeeto/hash-prospector
for the same purpose.
The hashmap is used to store thread status information in a
globally accessible location. It is a global variable.


## Mutex

The mutex is implemented via a ticketing system. On lock
a thread atomically gets a ticket (add_one_atomic) and
waits until it is their turn. To solve the problem of
communication among threads (ie. thread 7 should let
thread 8 know it is done) we use a shared memory location,
namely the now_serving variable.

Threads repeatedly check it, yielding to the current lock
owner to avoid wasting cycles, and eventually acquire the lock.

Unlocking simply consists of update the now_serving variable
with a blind write.


## Condition Variables

Condition variables were implemented with a queue of waiting threads that
are descheduled. When a thread calls con_wait() on a condition variable
cv, it is added to a queue of sleeping threads and then descheduled. Note
that we refrain from memory allocation by stack allocating the node which
we are putting into the queue. This node has a fixed size and does not
use much memory on the stack. Furthermore, note that if users illegally
call cond_destroy() on a condition variable while another thread is
in the midst of calling cond_wait(), cond_signal(), or cond_broadcast() on the
same condition variable, we will have undefined behavior in the form of a race
condition. This is because con_wait(), con_signal(), con_broadcast() first
affirm that the cond var is initialized before grabbing the mutex lock. Between
checking for initialization and grabbing the lock, an illegal call to
cond_destroy() will present a race, destroying the con var before the lock
can be grabbed. However, we had implemented a global mutex lock for all
cond vars to prevent this from happening, and multi threaded performance
was significantly slowed down. Because this race can only arise from an
illegal call to con_destroy(), we do not sacrifice such great time
resource just to avoid it.

To avoid interference from other programs calling make_runnable we use
a variable named should_wakeup to keep track of whether cond_signal was
the one who woke us up.


## Thread API

Only the root thread will be running on the initial stack space allocated
by the kernel. Since all threads share the same virtual address space, child
thread stacks are allocated in the heap via thread safe calls to malloc().
Fundamentally allocating stacks in the virtual address stack or the heap uses
calls to new_pages and so there is not an overly significant difference in
performance.

Every child thread stack also has an exception handler stack at its base. This
allows zero overlap between exception stacks of different children. All
important information of a thread is stored in a thread control block of
type thr_status_t. And this is stored in a global hashtable to enable quick
lookup when cleaning up after an exited thread.


## Semaphore

Semaphores were implemented with mutexes and condition variabls since
cond vars have an implicit queue. The OSC 10 definition of semaphores is used
where we block threads while count <= 0, and unblock otherwise.


## Read/Write locks

A read/write lock must allow either one writer or multiple readers
at a time. The approach here is to try and serve readers or writers
roughly in the order of arrival. Suppose the following order of
requests:

W1 R1 R2 W2

Then, we could avoid starvation of readers and writers by letting
W1 go first, then once its done we let R1 R2 go simulateneously,
and lastly, we let W2 go. However, this simple policy is can be rather
bad. Suppose the following sequence:

W1 R1 R2 W2 R3 R4

Then, if we had known of requests R3 and R4 before W1 gave
up its lock, we could reorganize our serving order as:

W1 R1 R2 R3 R4 W2

This enables us to serve all 4 readers in parallel. To enable
this "coalescing" of readers we make the following policy:

- Write requests go into a writer queue
- Read requests go into a reader queue
- Whenever we transition from WRITING to READING we service *all*
  read requests.

This simple policy equates to "coalescing" all reads together.
Wouldn't this lead to a starvation of writers, though? No. To avoid
the starvation of writers, we only coalesce when a writer has the lock.
When we are in the reading phase we accept no new readers.

Formulated more simply, we only "coalesce" readers during phase
transitions, which allows us to avoid starvation while enabling
high read parallelism.



*/

